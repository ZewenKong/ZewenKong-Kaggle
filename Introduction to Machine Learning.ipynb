{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4de8a76d-929b-45f1-979f-816f68ed58b7",
   "metadata": {},
   "source": [
    "### Data Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d63b23-d16c-4fea-b7d7-48bf1a7150f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1de7c3e5-aa66-461c-beb3-9906ae473563",
   "metadata": {},
   "source": [
    "# Explore the data\n",
    "# Set path\n",
    "example_path = \"path to this file\"\n",
    "\n",
    "# Read the data and store data\n",
    "example_data = pd.read_csv(example_path)\n",
    "\n",
    "# print a summary of the data\n",
    "example_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e5576c-6706-4458-ab81-eb3ac03aff51",
   "metadata": {},
   "source": [
    "### Model Building - Data Selecting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e21635b0-ef4e-4f6e-b406-372ef431f94a",
   "metadata": {},
   "source": [
    "# Selecting data (for modeling)\n",
    "\n",
    "# List all columns in the data set\n",
    "example_data.columns\n",
    "\n",
    "# Drop (missing) data -- \"dropna\"\n",
    "example_data = example_data.dropna(axis=0)\n",
    "\n",
    "# Select a subset of data want to predict (use the \"Dot Notation\" to select the column)\n",
    "y = example_data.columnName\n",
    "\n",
    "# Select features (features: the columns used to determine the predict value (所要预测的值))\n",
    "example_features = [\"f1\", \"f2\", \"f3\"]\n",
    "X = example_data[example_features]\n",
    "\n",
    "# Print a summary of the features\n",
    "X.describe()\n",
    "\n",
    "# Show top few rows\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd056e95-9110-4230-96fc-0e34109cc519",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3d5128-3486-4dc9-91f2-80f5e42126de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4770dcd3-c638-4a7f-a183-f426c376d77e",
   "metadata": {},
   "source": [
    "# Build the model (use the \"scikit-learn\" liberary)\n",
    "# Scikit-learn is easily the most popular library for modeling the types of data typically stored in DataFrames"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1820375-c44b-48b6-99d5-40bfc660e93f",
   "metadata": {},
   "source": [
    "# Steps to building a model\n",
    "# 1) Define; 2) Fit; 3) Predict, and 4) Evaluate"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e7c6a1a-f31c-457b-9a9c-1771d0e31158",
   "metadata": {},
   "source": [
    "# Define model\n",
    "# Specify a number for \"random_state\" to ensure same results each run\n",
    "# \"random_state\" 是 scikit-learn 内的参数, 许多 Machine Learning models 允许模型训练具有一定的随机性\n",
    "example_model = DecisionTreeRegressor(random_state = 1)\n",
    "\n",
    "# Fit model\n",
    "example_model.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "example_model.predict(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d90cb-81ab-41d6-ad40-90260bcb811d",
   "metadata": {},
   "source": [
    "### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc08278c-b109-490f-9cef-bcbf34b40f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e68ddc1-85af-4d3d-8dc2-8ad2e4f834c2",
   "metadata": {},
   "source": [
    "# Mean Absoulte Error \"MAE\"\n",
    "# Calculate the MAE\n",
    "\n",
    "predict_value = sample_model.predict(X)\n",
    "mean_absolute_error(y, predict_value)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "821c95c4-3090-4cbe-815d-737d9fdf2404",
   "metadata": {},
   "source": [
    "Since models' practical value come from making predictions on new data, we measure performance on data that wasn't used to build the model. The most straightforward way to do this is to exclude some data from the model-building process, and then use those to test the model's accuracy on data it hasn't seen before. This data is called \"validation data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e06ea1d-dc51-4ae3-9160-b10508938c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2818167b-df0d-4839-b361-d5bfced227d2",
   "metadata": {},
   "source": [
    "# Function \"train_test_split\" break up the data into two pieces.\n",
    "\n",
    "# Split data into training and validation data, for both features and target, the split is based on a random number generator. Supplying a numeric value to the random_state argument guarantees we get the same split every time we run this script.\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "# Define model\n",
    "sample_model = DecisionTreeRegressor()\n",
    "\n",
    "# Fit model\n",
    "sample_model.fit(train_X, train_y)\n",
    "\n",
    "# Get predicted prices on validation data\n",
    "val_predictions = sample_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d70633-1503-4d8c-93fe-66041b8fcd01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
